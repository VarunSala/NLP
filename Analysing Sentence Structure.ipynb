{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "from nltk import ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import RegexpParser as regex_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_gs = \"C:\\Program Files\\gs\\gs9.52\\bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PATH'] += os.pathsep + path_to_gs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NounPhrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"The little mouse ate the hot fresh cheese\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokens = nltk.pos_tag(word_tokenize(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('little', 'JJ'),\n",
       " ('mouse', 'NN'),\n",
       " ('ate', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('hot', 'JJ'),\n",
       " ('fresh', 'JJ'),\n",
       " ('cheese', 'NN')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammer_np = r\"NP: {<DT>?<JJ>*<NN>}\" # ? -- either 0 or 1, * -- either 0 or many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_parser = regex_parser(grammer_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP The/DT little/JJ mouse/NN)\n",
      "  ate/VB\n",
      "  (NP the/DT hot/JJ fresh/JJ cheese/NN))\n"
     ]
    }
   ],
   "source": [
    "chunk_result = chunk_parser.parse(sent_tokens)\n",
    "print(chunk_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VerbPhrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VP: {<PRP>?<VB|VBD|VBZ|VBG>*<RB|RBR>?}'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammer_vp = r\"VP: {<PRP>?<VB|VBD|VBZ|VBG>*<RB|RBR>?}\"\n",
    "grammer_vp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_parser2 = regex_parser(grammer_vp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('She', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('not', 'RB'),\n",
       " ('walking', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('mall', 'NN')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2 = \"She is not walking to the mall\"\n",
    "sent_tokens2 = nltk.pos_tag(word_tokenize(sent2))\n",
    "sent_tokens2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (VP She/PRP is/VBZ not/RB) (VP walking/VBG) to/TO the/DT mall/NN)\n"
     ]
    }
   ],
   "source": [
    "chunk_result2 = chunk_parser2.parse(sent_tokens2)\n",
    "print(chunk_result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('She', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('walking', 'VBG'),\n",
       " ('quickly', 'RB'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('mall', 'NN')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent3 = \"She is walking quickly to the mall\"\n",
    "sent_tokens3 = nltk.pos_tag(word_tokenize(sent3))\n",
    "sent_tokens3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (VP She/PRP is/VBZ walking/VBG quickly/RB) to/TO the/DT mall/NN)\n"
     ]
    }
   ],
   "source": [
    "chunk_result3 = chunk_parser2.parse(sent_tokens3)\n",
    "print(chunk_result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('She', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('walking', 'VBG'),\n",
       " ('very', 'RB'),\n",
       " ('quickly', 'RB'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('mall', 'NN')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent4 = \"She is walking very quickly to the mall\"\n",
    "sent_tokens4 = nltk.pos_tag(word_tokenize(sent4))\n",
    "sent_tokens4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (VP She/PRP is/VBZ walking/VBG very/RB)\n",
      "  (VP quickly/RB)\n",
      "  to/TO\n",
      "  the/DT\n",
      "  mall/NN)\n"
     ]
    }
   ],
   "source": [
    "chunk_result4 = chunk_parser2.parse(sent_tokens4)\n",
    "print(chunk_result4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "chink_grammar = r\"\"\"\n",
    "chk_name: \n",
    "{<PRP>?<VB|VBD|VBZ|VBG>*<RB|RBR>?} \n",
    "}<RB>+{\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chink_parser = nltk.RegexpParser(chink_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (chk_name She/PRP is/VBZ walking/VBG)\n",
      "  very/RB\n",
      "  quickly/RB\n",
      "  to/TO\n",
      "  the/DT\n",
      "  mall/NN)\n"
     ]
    }
   ],
   "source": [
    "print(chink_parser.parse(sent_tokens4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Free Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP \n",
    "VP -> V N \n",
    "V -> \"saw\"|\"met\" \n",
    "NP -> \"John\"|\"Jim\" \n",
    "N -> \"dog\"|\"cat\" \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John saw dog\n",
      "John saw cat\n",
      "John met dog\n",
      "John met cat\n",
      "Jim saw dog\n",
      "Jim saw cat\n",
      "Jim met dog\n",
      "Jim met cat\n"
     ]
    }
   ],
   "source": [
    "for sentence in generate(CFG_grammar):\n",
    "    print(\" \".join(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Production Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[S -> NP VP,\n",
       " VP -> V N,\n",
       " V -> 'saw',\n",
       " V -> 'met',\n",
       " NP -> 'John',\n",
       " NP -> 'Jim',\n",
       " N -> 'dog',\n",
       " N -> 'cat']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG_grammar.productions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Grammar with 8 productions>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG_grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CFG Implementation -- Automatic Text Paraphrasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cfg_parse(sentence):\n",
    "    sent_tk = nltk.pos_tag(word_tokenize(sentence)) \n",
    "    for one in sent_tk:\n",
    "        if one[1] == 'NNP':\n",
    "            s_NP = \"\\'\" + one[0]  + \"\\'\" \n",
    "        if one[1] == 'VBD' or one[1]=='VBN':\n",
    "            s_V = \"\\'\" + one[0] + \"\\'\" \n",
    "        if one[1] == 'NN': s_N = \"\\'\" + one[0] + \"\\'\" \n",
    "        else: pass\n",
    "    cfg_grammar2 = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    VP -> V N\n",
    "    NP -> {}\n",
    "    V -> {}\n",
    "    N -> {}\n",
    "    \"\"\".format(s_NP,s_V,s_N))\n",
    "    for sentence in generate(cfg_grammar2): \n",
    "        print(\" \".join(sentence)) \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John saw boat\n"
     ]
    }
   ],
   "source": [
    "cfg_parse(\"John saw a long white boat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('John', 'NNP'), ('saw', 'VBD'), ('boat', 'NN')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(word_tokenize(\"John saw boat\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
