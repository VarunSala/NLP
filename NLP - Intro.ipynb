{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Tokenization\\nLemmetization\\nStemming\\nStopwords , Punctuation_Removal\\nBiGrams / TriGrams / N-grams\\nPOS_Tagging / NER_Tagging'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Tokenization\n",
    "Lemmetization\n",
    "Stemming\n",
    "Stopwords , Punctuation_Removal\n",
    "BiGrams / TriGrams / N-grams\n",
    "POS_Tagging / NER_Tagging'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.data import load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing NLTK Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileSystemPathPointer('C:\\\\Users\\\\srnva\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.data.find('corpora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abc', 'abc.zip', 'alpino', 'alpino.zip', 'biocreative_ppi', 'biocreative_ppi.zip', 'brown', 'brown.zip', 'brown_tei', 'brown_tei.zip', 'cess_cat', 'cess_cat.zip', 'cess_esp', 'cess_esp.zip', 'chat80', 'chat80.zip', 'city_database', 'city_database.zip', 'cmudict', 'cmudict.zip', 'comparative_sentences', 'comparative_sentences.zip', 'comtrans.zip', 'conll2000', 'conll2000.zip', 'conll2002', 'conll2002.zip', 'conll2007.zip', 'crubadan', 'crubadan.zip', 'dependency_treebank', 'dependency_treebank.zip', 'dolch', 'dolch.zip', 'europarl_raw', 'europarl_raw.zip', 'floresta', 'floresta.zip', 'framenet_v15', 'framenet_v15.zip', 'framenet_v17', 'framenet_v17.zip', 'gazetteers', 'gazetteers.zip', 'genesis', 'genesis.zip', 'gutenberg', 'gutenberg.zip', 'ieer', 'ieer.zip', 'inaugural', 'inaugural.zip', 'indian', 'indian.zip', 'jeita.zip', 'kimmo', 'kimmo.zip', 'knbc.zip', 'lin_thesaurus', 'lin_thesaurus.zip', 'machado.zip', 'mac_morpho', 'mac_morpho.zip', 'masc_tagged.zip', 'movie_reviews', 'movie_reviews.zip', 'mte_teip5', 'mte_teip5.zip', 'names', 'names.zip', 'nombank.1.0.zip', 'nonbreaking_prefixes', 'nonbreaking_prefixes.zip', 'nps_chat', 'nps_chat.zip', 'omw', 'omw.zip', 'opinion_lexicon', 'opinion_lexicon.zip', 'panlex_swadesh.zip', 'paradigms', 'paradigms.zip', 'pil', 'pil.zip', 'pl196x', 'pl196x.zip', 'ppattach', 'ppattach.zip', 'problem_reports', 'problem_reports.zip', 'product_reviews_1', 'product_reviews_1.zip', 'product_reviews_2', 'product_reviews_2.zip', 'propbank.zip', 'pros_cons', 'pros_cons.zip', 'ptb', 'ptb.zip', 'qc', 'qc.zip', 'reuters.zip', 'rte', 'rte.zip', 'semcor.zip', 'senseval', 'senseval.zip', 'sentence_polarity', 'sentence_polarity.zip', 'sentiwordnet', 'sentiwordnet.zip', 'shakespeare', 'shakespeare.zip', 'sinica_treebank', 'sinica_treebank.zip', 'smultron', 'smultron.zip', 'state_union', 'state_union.zip', 'stopwords', 'stopwords.zip', 'subjectivity', 'subjectivity.zip', 'swadesh', 'swadesh.zip', 'switchboard', 'switchboard.zip', 'timit', 'timit.zip', 'toolbox', 'toolbox.zip', 'treebank', 'treebank.zip', 'twitter_samples', 'twitter_samples.zip', 'udhr', 'udhr.zip', 'udhr2', 'udhr2.zip', 'unicode_samples', 'unicode_samples.zip', 'universal_treebanks_v20.zip', 'verbnet', 'verbnet.zip', 'verbnet3', 'verbnet3.zip', 'webtext', 'webtext.zip', 'wordnet', 'wordnet.zip', 'wordnet_ic', 'wordnet_ic.zip', 'words', 'words.zip', 'ycoe', 'ycoe.zip']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(nltk.data.find('corpora')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.words('austen-emma.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'Persuasion', 'by', 'Jane', 'Austen', '1818', ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.words('austen-persuasion.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = \"\"\"Gold is a chemical element with symbol Au (from Latin: aurum) and atomic number 79, making it one of the higher atomic number elements that occur naturally. In its purest form, it is a bright, slightly reddish yellow, dense, soft, malleable, and ductile metal. Chemically, gold is a transition metal and a group 11 element. It is one of the least reactive chemical elements and is solid under standard conditions. Gold often occurs in free elemental (native) form, as nuggets or grains, in rocks, in veins, and in alluvial deposits. It occurs in a solid solution series with the native element silver (as electrum) and also naturally alloyed with copper and palladium. Less commonly, it occurs in minerals as gold compounds, often with tellurium (gold tellurides).\n",
    "\n",
    "\n",
    "Gold is resistant to most acids, though it does dissolve in aqua regia, a mixture of nitric acid and hydrochloric acid, which forms a soluble tetrachloroaurate anion. Gold is insoluble in nitric acid, which dissolves silver and base metals, a property that has long been used to refine gold and to confirm the presence of gold in metallic objects, giving rise to the term acid test. Gold also dissolves in alkaline solutions of cyanide, which are used in mining and electroplating. Gold dissolves in mercury, forming amalgam alloys, but this is not a chemical reaction.\n",
    "\n",
    "A relatively rare element,[5][6] gold is a precious metal that has been used for coinage, jewelry, and other arts throughout recorded history. In the past, a gold standard was often implemented as a monetary policy, but gold coins ceased to be minted as a circulating currency in the 1930s, and the world gold standard was abandoned for a fiat currency system after 1971.\n",
    "\n",
    "A total of 186,700 tonnes of gold exists above ground, as of 2015.[7] The world consumption of new gold produced is about 50% in jewelry, 40% in investments, and 10% in industry.[8] Gold's high malleability, ductility, resistance to corrosion and most other chemical reactions, and conductivity of electricity have led to its continued use in corrosion resistant electrical connectors in all types of computerized devices (its chief industrial use). Gold is also used in infrared shielding, colored-glass production, gold leafing, and tooth restoration. Certain gold salts are still used as anti-inflammatories in medicine. As of 2016, the world's largest gold producer by far was China with 450 tonnes per year\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_word_tokenize = word_tokenize(gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gold',\n",
       " 'is',\n",
       " 'a',\n",
       " 'chemical',\n",
       " 'element',\n",
       " 'with',\n",
       " 'symbol',\n",
       " 'Au',\n",
       " '(',\n",
       " 'from',\n",
       " 'Latin',\n",
       " ':',\n",
       " 'aurum',\n",
       " ')',\n",
       " 'and',\n",
       " 'atomic',\n",
       " 'number',\n",
       " '79',\n",
       " ',',\n",
       " 'making',\n",
       " 'it',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'higher',\n",
       " 'atomic',\n",
       " 'number',\n",
       " 'elements',\n",
       " 'that',\n",
       " 'occur',\n",
       " 'naturally',\n",
       " '.',\n",
       " 'In',\n",
       " 'its',\n",
       " 'purest',\n",
       " 'form',\n",
       " ',',\n",
       " 'it',\n",
       " 'is',\n",
       " 'a',\n",
       " 'bright',\n",
       " ',',\n",
       " 'slightly',\n",
       " 'reddish',\n",
       " 'yellow',\n",
       " ',',\n",
       " 'dense',\n",
       " ',',\n",
       " 'soft',\n",
       " ',',\n",
       " 'malleable',\n",
       " ',',\n",
       " 'and',\n",
       " 'ductile',\n",
       " 'metal',\n",
       " '.',\n",
       " 'Chemically',\n",
       " ',',\n",
       " 'gold',\n",
       " 'is',\n",
       " 'a',\n",
       " 'transition',\n",
       " 'metal',\n",
       " 'and',\n",
       " 'a',\n",
       " 'group',\n",
       " '11',\n",
       " 'element',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'least',\n",
       " 'reactive',\n",
       " 'chemical',\n",
       " 'elements',\n",
       " 'and',\n",
       " 'is',\n",
       " 'solid',\n",
       " 'under',\n",
       " 'standard',\n",
       " 'conditions',\n",
       " '.',\n",
       " 'Gold',\n",
       " 'often',\n",
       " 'occurs',\n",
       " 'in',\n",
       " 'free',\n",
       " 'elemental',\n",
       " '(',\n",
       " 'native',\n",
       " ')',\n",
       " 'form',\n",
       " ',',\n",
       " 'as',\n",
       " 'nuggets',\n",
       " 'or',\n",
       " 'grains',\n",
       " ',',\n",
       " 'in',\n",
       " 'rocks',\n",
       " ',',\n",
       " 'in',\n",
       " 'veins',\n",
       " ',',\n",
       " 'and',\n",
       " 'in',\n",
       " 'alluvial',\n",
       " 'deposits',\n",
       " '.',\n",
       " 'It',\n",
       " 'occurs',\n",
       " 'in',\n",
       " 'a',\n",
       " 'solid',\n",
       " 'solution',\n",
       " 'series',\n",
       " 'with',\n",
       " 'the',\n",
       " 'native',\n",
       " 'element',\n",
       " 'silver',\n",
       " '(',\n",
       " 'as',\n",
       " 'electrum',\n",
       " ')',\n",
       " 'and',\n",
       " 'also',\n",
       " 'naturally',\n",
       " 'alloyed',\n",
       " 'with',\n",
       " 'copper',\n",
       " 'and',\n",
       " 'palladium',\n",
       " '.',\n",
       " 'Less',\n",
       " 'commonly',\n",
       " ',',\n",
       " 'it',\n",
       " 'occurs',\n",
       " 'in',\n",
       " 'minerals',\n",
       " 'as',\n",
       " 'gold',\n",
       " 'compounds',\n",
       " ',',\n",
       " 'often',\n",
       " 'with',\n",
       " 'tellurium',\n",
       " '(',\n",
       " 'gold',\n",
       " 'tellurides',\n",
       " ')',\n",
       " '.',\n",
       " 'Gold',\n",
       " 'is',\n",
       " 'resistant',\n",
       " 'to',\n",
       " 'most',\n",
       " 'acids',\n",
       " ',',\n",
       " 'though',\n",
       " 'it',\n",
       " 'does',\n",
       " 'dissolve',\n",
       " 'in',\n",
       " 'aqua',\n",
       " 'regia',\n",
       " ',',\n",
       " 'a',\n",
       " 'mixture',\n",
       " 'of',\n",
       " 'nitric',\n",
       " 'acid',\n",
       " 'and',\n",
       " 'hydrochloric',\n",
       " 'acid',\n",
       " ',',\n",
       " 'which',\n",
       " 'forms',\n",
       " 'a',\n",
       " 'soluble',\n",
       " 'tetrachloroaurate',\n",
       " 'anion',\n",
       " '.',\n",
       " 'Gold',\n",
       " 'is',\n",
       " 'insoluble',\n",
       " 'in',\n",
       " 'nitric',\n",
       " 'acid',\n",
       " ',',\n",
       " 'which',\n",
       " 'dissolves',\n",
       " 'silver',\n",
       " 'and',\n",
       " 'base',\n",
       " 'metals',\n",
       " ',',\n",
       " 'a',\n",
       " 'property',\n",
       " 'that',\n",
       " 'has',\n",
       " 'long',\n",
       " 'been',\n",
       " 'used',\n",
       " 'to',\n",
       " 'refine',\n",
       " 'gold',\n",
       " 'and',\n",
       " 'to',\n",
       " 'confirm',\n",
       " 'the',\n",
       " 'presence',\n",
       " 'of',\n",
       " 'gold',\n",
       " 'in',\n",
       " 'metallic',\n",
       " 'objects',\n",
       " ',',\n",
       " 'giving',\n",
       " 'rise',\n",
       " 'to',\n",
       " 'the',\n",
       " 'term',\n",
       " 'acid',\n",
       " 'test',\n",
       " '.',\n",
       " 'Gold',\n",
       " 'also',\n",
       " 'dissolves',\n",
       " 'in',\n",
       " 'alkaline',\n",
       " 'solutions',\n",
       " 'of',\n",
       " 'cyanide',\n",
       " ',',\n",
       " 'which',\n",
       " 'are',\n",
       " 'used',\n",
       " 'in',\n",
       " 'mining',\n",
       " 'and',\n",
       " 'electroplating',\n",
       " '.',\n",
       " 'Gold',\n",
       " 'dissolves',\n",
       " 'in',\n",
       " 'mercury',\n",
       " ',',\n",
       " 'forming',\n",
       " 'amalgam',\n",
       " 'alloys',\n",
       " ',',\n",
       " 'but',\n",
       " 'this',\n",
       " 'is',\n",
       " 'not',\n",
       " 'a',\n",
       " 'chemical',\n",
       " 'reaction',\n",
       " '.',\n",
       " 'A',\n",
       " 'relatively',\n",
       " 'rare',\n",
       " 'element',\n",
       " ',',\n",
       " '[',\n",
       " '5',\n",
       " ']',\n",
       " '[',\n",
       " '6',\n",
       " ']',\n",
       " 'gold',\n",
       " 'is',\n",
       " 'a',\n",
       " 'precious',\n",
       " 'metal',\n",
       " 'that',\n",
       " 'has',\n",
       " 'been',\n",
       " 'used',\n",
       " 'for',\n",
       " 'coinage',\n",
       " ',',\n",
       " 'jewelry',\n",
       " ',',\n",
       " 'and',\n",
       " 'other',\n",
       " 'arts',\n",
       " 'throughout',\n",
       " 'recorded',\n",
       " 'history',\n",
       " '.',\n",
       " 'In',\n",
       " 'the',\n",
       " 'past',\n",
       " ',',\n",
       " 'a',\n",
       " 'gold',\n",
       " 'standard',\n",
       " 'was',\n",
       " 'often',\n",
       " 'implemented',\n",
       " 'as',\n",
       " 'a',\n",
       " 'monetary',\n",
       " 'policy',\n",
       " ',',\n",
       " 'but',\n",
       " 'gold',\n",
       " 'coins',\n",
       " 'ceased',\n",
       " 'to',\n",
       " 'be',\n",
       " 'minted',\n",
       " 'as',\n",
       " 'a',\n",
       " 'circulating',\n",
       " 'currency',\n",
       " 'in',\n",
       " 'the',\n",
       " '1930s',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'world',\n",
       " 'gold',\n",
       " 'standard',\n",
       " 'was',\n",
       " 'abandoned',\n",
       " 'for',\n",
       " 'a',\n",
       " 'fiat',\n",
       " 'currency',\n",
       " 'system',\n",
       " 'after',\n",
       " '1971',\n",
       " '.',\n",
       " 'A',\n",
       " 'total',\n",
       " 'of',\n",
       " '186,700',\n",
       " 'tonnes',\n",
       " 'of',\n",
       " 'gold',\n",
       " 'exists',\n",
       " 'above',\n",
       " 'ground',\n",
       " ',',\n",
       " 'as',\n",
       " 'of',\n",
       " '2015',\n",
       " '.',\n",
       " '[',\n",
       " '7',\n",
       " ']',\n",
       " 'The',\n",
       " 'world',\n",
       " 'consumption',\n",
       " 'of',\n",
       " 'new',\n",
       " 'gold',\n",
       " 'produced',\n",
       " 'is',\n",
       " 'about',\n",
       " '50',\n",
       " '%',\n",
       " 'in',\n",
       " 'jewelry',\n",
       " ',',\n",
       " '40',\n",
       " '%',\n",
       " 'in',\n",
       " 'investments',\n",
       " ',',\n",
       " 'and',\n",
       " '10',\n",
       " '%',\n",
       " 'in',\n",
       " 'industry',\n",
       " '.',\n",
       " '[',\n",
       " '8',\n",
       " ']',\n",
       " 'Gold',\n",
       " \"'s\",\n",
       " 'high',\n",
       " 'malleability',\n",
       " ',',\n",
       " 'ductility',\n",
       " ',',\n",
       " 'resistance',\n",
       " 'to',\n",
       " 'corrosion',\n",
       " 'and',\n",
       " 'most',\n",
       " 'other',\n",
       " 'chemical',\n",
       " 'reactions',\n",
       " ',',\n",
       " 'and',\n",
       " 'conductivity',\n",
       " 'of',\n",
       " 'electricity',\n",
       " 'have',\n",
       " 'led',\n",
       " 'to',\n",
       " 'its',\n",
       " 'continued',\n",
       " 'use',\n",
       " 'in',\n",
       " 'corrosion',\n",
       " 'resistant',\n",
       " 'electrical',\n",
       " 'connectors',\n",
       " 'in',\n",
       " 'all',\n",
       " 'types',\n",
       " 'of',\n",
       " 'computerized',\n",
       " 'devices',\n",
       " '(',\n",
       " 'its',\n",
       " 'chief',\n",
       " 'industrial',\n",
       " 'use',\n",
       " ')',\n",
       " '.',\n",
       " 'Gold',\n",
       " 'is',\n",
       " 'also',\n",
       " 'used',\n",
       " 'in',\n",
       " 'infrared',\n",
       " 'shielding',\n",
       " ',',\n",
       " 'colored-glass',\n",
       " 'production',\n",
       " ',',\n",
       " 'gold',\n",
       " 'leafing',\n",
       " ',',\n",
       " 'and',\n",
       " 'tooth',\n",
       " 'restoration',\n",
       " '.',\n",
       " 'Certain',\n",
       " 'gold',\n",
       " 'salts',\n",
       " 'are',\n",
       " 'still',\n",
       " 'used',\n",
       " 'as',\n",
       " 'anti-inflammatories',\n",
       " 'in',\n",
       " 'medicine',\n",
       " '.',\n",
       " 'As',\n",
       " 'of',\n",
       " '2016',\n",
       " ',',\n",
       " 'the',\n",
       " 'world',\n",
       " \"'s\",\n",
       " 'largest',\n",
       " 'gold',\n",
       " 'producer',\n",
       " 'by',\n",
       " 'far',\n",
       " 'was',\n",
       " 'China',\n",
       " 'with',\n",
       " '450',\n",
       " 'tonnes',\n",
       " 'per',\n",
       " 'year']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gold_word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in gold_word_tokenize:\n",
    "    fdist[word.lower()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 78, 'in': 42, '.': 36, 'gold': 36, 'and': 34, 'a': 30, 'of': 24, 'is': 22, 'the': 19, 'as': 15, ...})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist['gold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist_top10 = fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 78),\n",
       " ('in', 42),\n",
       " ('.', 36),\n",
       " ('gold', 36),\n",
       " ('and', 34),\n",
       " ('a', 30),\n",
       " ('of', 24),\n",
       " ('is', 22),\n",
       " ('the', 19),\n",
       " ('as', 15)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_top10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StopWords & Punctuations\n",
    "#### Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_english = set(stopwords.words('english'))\n",
    "stopwords_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_word_tokenize = [word.lower() for word in gold_word_tokenize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_stopwords = [word for word in gold_word_tokenize if word not in stopwords_english]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(326, 479)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(post_stopwords), len(gold_word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "punctuations = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_punctuation = [word for word in gold_word_tokenize if word not in punctuations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 479)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(post_punctuation), len(gold_word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Stopwords & punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_stopwords_punctuations = [word for word in gold_word_tokenize if word not in stopwords_english and word not in punctuations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(479, 326, 400, 247)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gold_word_tokenize), len(post_stopwords), len(post_punctuation), len(post_stopwords_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist_new = FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in post_stopwords_punctuations:\n",
    "    fdist_new[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'gold': 22, 'used': 5, 'chemical': 4, 'element': 4, 'acid': 4, 'metal': 3, 'standard': 3, 'often': 3, 'occurs': 3, 'also': 3, ...})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fdist_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gold', 22),\n",
       " ('used', 5),\n",
       " ('chemical', 4),\n",
       " ('element', 4),\n",
       " ('acid', 4),\n",
       " ('metal', 3),\n",
       " ('standard', 3),\n",
       " ('often', 3),\n",
       " ('occurs', 3),\n",
       " ('also', 3)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_new.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Expression Tokenize & Blank line Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import regexp_tokenize, blankline_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['79',\n",
       " '11',\n",
       " '5',\n",
       " '6',\n",
       " '1930',\n",
       " '1971',\n",
       " '186',\n",
       " '700',\n",
       " '2015',\n",
       " '7',\n",
       " '50',\n",
       " '40',\n",
       " '10',\n",
       " '8',\n",
       " '2016',\n",
       " '450']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp_tokenize(gold, pattern='\\d+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_bl_tokenize = blankline_tokenize(gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gold_bl_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gold is a chemical element with symbol Au (from Latin: aurum) and atomic number 79, making it one of the higher atomic number elements that occur naturally. In its purest form, it is a bright, slightly reddish yellow, dense, soft, malleable, and ductile metal. Chemically, gold is a transition metal and a group 11 element. It is one of the least reactive chemical elements and is solid under standard conditions. Gold often occurs in free elemental (native) form, as nuggets or grains, in rocks, in veins, and in alluvial deposits. It occurs in a solid solution series with the native element silver (as electrum) and also naturally alloyed with copper and palladium. Less commonly, it occurs in minerals as gold compounds, often with tellurium (gold tellurides).'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_bl_tokenize[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_sent_tokenize = sent_tokenize(gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gold is a chemical element with symbol Au (from Latin: aurum) and atomic number 79, making it one of the higher atomic number elements that occur naturally.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_sent_tokenize[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'have'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem(\"having\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'give'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem(\"giving\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'had'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem(\"had\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_stem = ['give', 'gave', 'given', 'giving', 'studying']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give:give\n",
      "gave:gave\n",
      "given:given\n",
      "giving:give\n",
      "studying:studi\n"
     ]
    }
   ],
   "source": [
    "for words in words_to_stem:\n",
    "    print(words+\":\"+pst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give:giv\n",
      "gave:gav\n",
      "given:giv\n",
      "giving:giv\n",
      "studying:study\n"
     ]
    }
   ],
   "source": [
    "for words in words_to_stem:\n",
    "    print(words+\":\"+lst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbst = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('arabic',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'hungarian',\n",
       " 'italian',\n",
       " 'norwegian',\n",
       " 'porter',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'spanish',\n",
       " 'swedish')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbst.languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'have'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbst.stem('having')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give:give\n",
      "gave:gave\n",
      "given:given\n",
      "giving:give\n",
      "studying:studi\n"
     ]
    }
   ],
   "source": [
    "for words in words_to_stem:\n",
    "    print(words+\":\"+sbst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemms(word):\n",
    "    print(\"Porter :\"+pst.stem(word))\n",
    "    print(\"Lancaster :\"+lst.stem(word))\n",
    "    print(\"Snowball :\"+pst.stem(word))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter :take\n",
      "Lancaster :tak\n",
      "Snowball :take\n"
     ]
    }
   ],
   "source": [
    "stemms('taking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter :data\n",
      "Lancaster :dat\n",
      "Snowball :data\n"
     ]
    }
   ],
   "source": [
    "stemms('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter :corpora\n",
      "Lancaster :corpor\n",
      "Snowball :corpora\n"
     ]
    }
   ],
   "source": [
    "stemms('corpora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter :curricula\n",
      "Lancaster :curricul\n",
      "Snowball :curricula\n"
     ]
    }
   ],
   "source": [
    "stemms('curricula')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter :curriculum\n",
      "Lancaster :curricul\n",
      "Snowball :curriculum\n"
     ]
    }
   ],
   "source": [
    "stemms('curriculum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import wordnet\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'corpus'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lem.lemmatize(\"corpora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'curriculum'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lem.lemmatize(\"curricula\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give: give\n",
      "gave: gave\n",
      "given: given\n",
      "giving: giving\n",
      "studying: studying\n"
     ]
    }
   ],
   "source": [
    "for words in words_to_stem:\n",
    "    print(words+\": \"+word_lem.lemmatize(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigrams, Trigrams, Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import bigrams, trigrams, ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"The Mona Lisa is a half length portrait painting by the Italian Renaissance artist Leonardo da Vinci\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "mona_lis_tokens = word_tokenize(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mona_lis_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_grams = list(nltk.bigrams(mona_lis_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'Mona'),\n",
       " ('Mona', 'Lisa'),\n",
       " ('Lisa', 'is'),\n",
       " ('is', 'a'),\n",
       " ('a', 'half'),\n",
       " ('half', 'length'),\n",
       " ('length', 'portrait'),\n",
       " ('portrait', 'painting'),\n",
       " ('painting', 'by'),\n",
       " ('by', 'the'),\n",
       " ('the', 'Italian'),\n",
       " ('Italian', 'Renaissance'),\n",
       " ('Renaissance', 'artist'),\n",
       " ('artist', 'Leonardo'),\n",
       " ('Leonardo', 'da'),\n",
       " ('da', 'Vinci')]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'Mona', 'Lisa'),\n",
       " ('Mona', 'Lisa', 'is'),\n",
       " ('Lisa', 'is', 'a'),\n",
       " ('is', 'a', 'half'),\n",
       " ('a', 'half', 'length'),\n",
       " ('half', 'length', 'portrait'),\n",
       " ('length', 'portrait', 'painting'),\n",
       " ('portrait', 'painting', 'by'),\n",
       " ('painting', 'by', 'the'),\n",
       " ('by', 'the', 'Italian'),\n",
       " ('the', 'Italian', 'Renaissance'),\n",
       " ('Italian', 'Renaissance', 'artist'),\n",
       " ('Renaissance', 'artist', 'Leonardo'),\n",
       " ('artist', 'Leonardo', 'da'),\n",
       " ('Leonardo', 'da', 'Vinci')]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_grams = list(nltk.trigrams(mona_lis_tokens))\n",
    "tri_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'Mona', 'Lisa', 'is', 'a'),\n",
       " ('Mona', 'Lisa', 'is', 'a', 'half'),\n",
       " ('Lisa', 'is', 'a', 'half', 'length'),\n",
       " ('is', 'a', 'half', 'length', 'portrait'),\n",
       " ('a', 'half', 'length', 'portrait', 'painting'),\n",
       " ('half', 'length', 'portrait', 'painting', 'by'),\n",
       " ('length', 'portrait', 'painting', 'by', 'the'),\n",
       " ('portrait', 'painting', 'by', 'the', 'Italian'),\n",
       " ('painting', 'by', 'the', 'Italian', 'Renaissance'),\n",
       " ('by', 'the', 'Italian', 'Renaissance', 'artist'),\n",
       " ('the', 'Italian', 'Renaissance', 'artist', 'Leonardo'),\n",
       " ('Italian', 'Renaissance', 'artist', 'Leonardo', 'da'),\n",
       " ('Renaissance', 'artist', 'Leonardo', 'da', 'Vinci')]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_grams = list(nltk.ngrams(mona_lis_tokens, 5))\n",
    "n_grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jim', 'eats', 'a', 'banana']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Jim eats a banana\"\n",
    "sent_tokens = word_tokenize(sentence)\n",
    "sent_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Jim', 'NNP')]\n",
      "[('eats', 'NNS')]\n",
      "[('a', 'DT')]\n",
      "[('banana', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "for token in sent_tokens:\n",
    "    print(nltk.pos_tag([token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Dog', 'chased', 'the', 'Cat']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"The Dog chased the Cat\"\n",
    "sent_tokens = word_tokenize(sentence)\n",
    "sent_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT')]\n",
      "[('Dog', 'NN')]\n",
      "[('chased', 'VBN')]\n",
      "[('the', 'DT')]\n",
      "[('Cat', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "for token in sent_tokens:\n",
    "    print(nltk.pos_tag([token]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penn Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_sentences = nltk.corpus.treebank.tagged_sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(tagged_sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER Tagging  (Named Entity Recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "NE_sent = \"The US President stays in the White House\"\n",
    "NE_tokens = word_tokenize(NE_sent)\n",
    "NE_tags = nltk.pos_tag(NE_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('US', 'NNP'),\n",
       " ('President', 'NNP'),\n",
       " ('stays', 'VBZ'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('White', 'NNP'),\n",
       " ('House', 'NNP')]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NE_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  The/DT\n",
      "  (ORGANIZATION US/NNP)\n",
      "  President/NNP\n",
      "  stays/VBZ\n",
      "  in/IN\n",
      "  the/DT\n",
      "  (FACILITY White/NNP House/NNP))\n"
     ]
    }
   ],
   "source": [
    "NE_NER = ne_chunk(NE_tags)\n",
    "print(NE_NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srnva\\Anaconda3\\lib\\site-packages\\spacy\\displacy\\__init__.py:94: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
      "  warnings.warn(Warnings.W011)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">When \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sebastian Thrun\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " started working on self-driving cars at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2007\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", few people outside of the company took him seriously.</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'ent' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "text = \"When Sebastian Thrun started working on self-driving cars at Google in 2007, few people outside of the company took him seriously.\"\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "displacy.serve(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"When Sebastian Thrun started working on self-driving cars at Google in 2007, few people outside of the company took him seriously. “I can tell you very senior CEOs of major American car companies would shake my hand and turn away because I wasn’t worth talking to,” said Thrun, now the co-founder and CEO of online higher education startup Udacity, in an interview with Recode earlier this week.A little less than a decade later, dozens of self-driving startups have cropped up while automakers around the world clamor, wallet in hand, to secure their place in the fast-moving world of fully automated transportation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srnva\\Anaconda3\\lib\\site-packages\\spacy\\displacy\\__init__.py:94: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
      "  warnings.warn(Warnings.W011)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">When \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sebastian Thrun\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " started working on self-driving cars at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2007\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", few people outside of the company took him seriously. “I can tell you very senior CEOs of major \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    American\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " car companies would shake my hand and turn away because I wasn’t worth talking to,” said \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Thrun\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", now the co-founder and CEO of online higher education startup Udacity, in an interview with \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Recode\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    earlier this week\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".A \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    little less than a decade later\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    dozens\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " of self-driving startups have cropped up while automakers around the world clamor, wallet in hand, to secure their place in the fast-moving world of fully automated transportation.</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'ent' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "spacy.displacy.serve(doc, style=\"ent\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
